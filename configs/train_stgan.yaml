# meta
exp_name: 128_dst
mode: train
split: True
cuda: True
ngpu: 1
gpus: '0'

# data
dataset: material
data_root: 'data_45k'
train_file: 'attributes_dataset_train_256_old.txt'
test_file: 'attributes_dataset_test_full_old.txt'
crop_size: 240
image_size: 128
data_augmentation: True
mask_input_bg: True
histogram: True
histogram_color_type: 'hsv'

# model
g_conv_dim: 64
d_conv_dim: 64
d_fc_dim: 1024
g_layers: 5
d_layers: 5
shortcut_layers: 4
stu_kernel_size: 3
use_stu: True
deconv: False
one_more_conv: True
checkpoint: 40000

# training
batch_size: 32
beta1: 0.5
beta2: 0.999
g_lr: 0.0002
d_lr: 0.0002
n_critic: 7
ld_n_critic: 10
thres_int: 1.0
thres_edition: 1.0
g_xavier_init: False
d_xavier_init: False
ld_xavier_init: False 
use_ld: False

# tradeoff parameters
lambda_gp: 10
lambda_1: 10 # att discriminator (original value = 1)
lambda_2: 100 # att generator (original value = 10)
lambda_3: 1000 # reconstruction generator (original value = 100)
lambda_4: 1 # adversarial discriminator
lambda_5: 1 # adversarial generator

# attributes
att_activation: 'sigmoid' # 'tanh', 'sigmoid' or ''
att_loss: 'l1' # 'l1', 'binary_cross_entropy' or 'cross_entropy'
att_max: 1
att_min: 0
num_samples: 9
att_neg: False
att_diff: False
attrs: [glossy]
uniform: True

# iterations
max_epochs: 300
lr_decay_iters: 10000000000000000

# steps:
summary_step: 20
sample_step: 750
checkpoint_step: 5000
